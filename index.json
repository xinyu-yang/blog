[{"categories":["algorithm"],"content":"算法介绍 按照出现时间，该算法比count-min sketch出现的时间更早，但似乎没有count-min sketch应用广泛。该算法的大体思想与count-min sketch相似，只是有少许不同。 首先介绍算法的过程，初始化$t$个独立的hash函数$h_1, h_2, …,h_t$，每一个hash函数都是从集合$[n] \\to [k]$的映射。同时还要初始化$t$个符号函数$s_i : [n] \\to [\\pm 1]$，然后初始化一个二维矩阵，如下图所示： 对于具有m个元素的集合A，对其进行如下操作: Set all $C_{i,j}=0$ for i=0 to m do for j=0 to t do $C_{j,h_{j}(a_i)}$ += $s_j (a_i)$ 该操作与count-min sketch唯一不同的点在于，最后加的值有可能是1或者-1。 当查找一个元素出现的次数时，只需要计算 $$\\check{f_{q}}=median\\ C_{j,h_{j}(q)},\\ j\\in [t]$$ 这里与count-min sketch不同的是，本方法所产生的值有可能是正也有可能是负，有可能假阳也有可能假阴，而count-min sketch中只有正，所以一定会产生假阳性。仅从直觉上来判断，似乎选中间值是合理的，因为正负相互抵消，比较理想的情况就是恰好抵消完，那就没有误差了。 ","date":"2021-04-12","objectID":"/posts/21-04-12_count-sketch/:1:0","tags":["hash","heavy hitter"],"title":"Count Sketch","uri":"/posts/21-04-12_count-sketch/"},{"categories":["algorithm"],"content":"分析 参考了几篇文章，甚至参考了作者的原文，其证明方法都不太一样，尴尬的是我一个都没看懂😂，哎~等能看懂再补上吧。。。 路漫漫其修远兮，吾将上下而求索啊 ","date":"2021-04-12","objectID":"/posts/21-04-12_count-sketch/:2:0","tags":["hash","heavy hitter"],"title":"Count Sketch","uri":"/posts/21-04-12_count-sketch/"},{"categories":["algorithm"],"content":"代码实现 参考文献 https://wangshusen.github.io/code/countsketch.html 中就有一个代码实现，而且有动态图展示。 ","date":"2021-04-12","objectID":"/posts/21-04-12_count-sketch/:3:0","tags":["hash","heavy hitter"],"title":"Count Sketch","uri":"/posts/21-04-12_count-sketch/"},{"categories":["algorithm"],"content":"参考文献 https://web.stanford.edu/class/cs369g/files/lectures/lec8.pdf https://www.cs.rutgers.edu/~farach/pubs/FrequentStream.pdf https://wangshusen.github.io/code/countsketch.html ","date":"2021-04-12","objectID":"/posts/21-04-12_count-sketch/:4:0","tags":["hash","heavy hitter"],"title":"Count Sketch","uri":"/posts/21-04-12_count-sketch/"},{"categories":["信口开河"],"content":" 最近看了一些科普方面的文章和视频，所以对气候变化这件事情有了一些思考，特此记录。因为只是作为个人天马行空思考的记录，所以并无科学严谨性可言，因此几乎不会引用任何的专业文献和专业数据。  我们现在在讨论气候变化的时候，总是在说由于人类活动的原因，使得全球气候变暖，或者森林遭到砍伐，土地荒漠化等。这些环境的变化在人类生存的历史上也许是重大的环境变迁，但是如果纵观地球的发展史，就会发现，相对于地球环境变化的惊涛骇浪，现在我们所经历的变化不过是平静湖面上的微波涟漪。 那么为什么我们会对现在的环境变化如此担忧呢？我感觉答案正如某院士（记不清楚名字）在采访时所说的那样，人类不是在保护环境，人类只不过是在保护自己。  地球的环境一直都处在变化当中，其中不乏有极端夸张的气候环境，极寒或者极热，但是地球也没出问题，所以现在地球出现的这点变化，还轮不到人类去拯救的地步。因此是不是可以理解为人类所拯救的那个“地球”只不过是人类所适宜生存的那个地球状态。 毕竟相对于地球气候变化的幅度，人类所能适宜生存的气候范围实在是太小了，人类的历史相对于地球生命的历史也不过是短短一瞬。  不得不感叹人类在大自然面前如此渺小，即使人类已经在科技方面取得了重大进步，已经具备了一定的抵御自然灾害的能力，甚至有时会产生人类已经战胜大自然的错觉。但是当我们面临大自然的时候，显得是那么的无能为力。人类毫无疑问是大自然的一部分，也就是从某种意义上讲人类能够对大自然所做的一切，也都是大自然的命运安排。这种宿命论似乎有些悲观，因为人类看似具备自我思考的能力，但很可能永远无法突破大自然的限制。但并不是说人类的探索都是没有意义的，毕竟不去探索，我们永远无法知道自己可以做到什么。  个人感觉人类应当具备适应环境变化的能力，而不是一直待在舒适圈里。因为也许人类的出现将不可避免地导致大自然朝向某个方向变化，即使人类真的能保护现有环境，抑制全球变暖，使这些较为明显的环境因素保持稳定，但是我们对地球地改变将潜移默化地从很多方面体现出来，也许是人类想象不到的方面。 如果人类不能适应现有生存环境之外的环境，那么终将有一天会为此付出惨痛的代价。 ","date":"2021-04-10","objectID":"/posts/21-04-10_climate-change/:0:0","tags":[],"title":"当我们在谈论环境保护的时候我们在谈论什么？","uri":"/posts/21-04-10_climate-change/"},{"categories":["algorithm"],"content":"摘要 该算法以hash函数为基础，主要用来解决membership问题，也就是判断某个元素在不在某个集合中，可以在常数时间进行判断，但是判断结果可能存在假阳性的问题，也就是一个元素不在集合中，但是却被误判为在。该算法的实现同样是采用了以减少精确度换取较小的空间开销的思想，具体损失多少精度，又能换回多少空间是本文要解决的问题。 ","date":"2021-04-07","objectID":"/posts/21-04-07_bloom-filter/:1:0","tags":["hash"],"title":"Bloom Filter","uri":"/posts/21-04-07_bloom-filter/"},{"categories":["algorithm"],"content":"算法 该算法很简单且优美，下面对其进行简单描述，首先初始化一个长度为$m$的比特串$B$，并选择$k$个$[N]\\to [m]$的hash函数，对于一个每一个元素都属于$[N]$的长度为$n$的集合$S$，对其进行如下操作： Set B[.]=0 for i=1 to n do for j=1 to k do $B[h_j(S_i)]=1$ 算法很简单，就是对每一个元素，用所有的hash函数进行计算，并将所计算出的所有位置置1。查找也很简单，就是进行类似的操作，如果元素$q$的所有的hash值对应的值均为1，那么就判断元素在该集合中。 显而易见，如果$q$真的在集合中，那么肯定能得到肯定的结果，但是得到肯定的结果不代表其一定位于集合中。因为会存在假阳性的问题，所以现在的问题就是如何评估假阳性出现的概率，以及如何选取$k$和$m$的值来使内存占用和准确度都能比较好呢？ ","date":"2021-04-07","objectID":"/posts/21-04-07_bloom-filter/:2:0","tags":["hash"],"title":"Bloom Filter","uri":"/posts/21-04-07_bloom-filter/"},{"categories":["algorithm"],"content":"分析 首先分析对于一个元素，其不在集合当中，但是将其判断为在集合当中的概率。假设该元素经过hash函数计算之后的值分别为$a_1, a_2, …, a_k$，对于任意一个$a_i$的值为0的概率为： $$ P(B[a_i]=0) = (1-1/m)^{nk} $$ 因为假设所有的元素的hash值服从均匀分布，所以落到每一点是等概率的$1/m$，而只有当所有元素的所有hash值（共$nk$个）都没落到$a_i$点，其值才为$0$。 然后计算一个元素假阳性的概率，其假阳性代表所有的hash值对应的点均为$1$，即： $$ P(\\forall.i\\ B[a_i]=1) = (1-(1-1/m)^{nk})^k $$ 然后又根据当$m$的值较大时的近似公式： $$ (1-1/m)^{nk}=e^{-nk/m} $$ 可以将上述公式化简为$(1-e^{-nk/m})^k$。我们希望该值尽可能的小，因此在$m,n$值确定的情况下，我们希望通过$k$值的选取使得其值尽可能的小，求$(1-e^{-nk/m})^k$的最小值就相当于求$k\\cdot ln(1-e^{-nk/m})$的最小值。求导应该可以算出来，但这里有一个技巧，我们假设$p=e^{-nk/m}$，则上式可以化为： $$-\\frac{m}{n} \\ln p\\ln(1-p)$$ 根据对称性，可知当$p$取$1/2$时，其值最小,此时k的值为$\\frac{m}{n} \\ln2$。该网站有一个相应的对应表格，我们截取一部分如下图所示： -- -- -- 从图中可以看出，当$m/n$比例一定时，假阳性的值随$k$先减小再增大，比如当$m/n=9$时，其最小值在$k=6$处取得。 我们已经算出了$k$的最优取值，将其代入到假阳性计算公式中可得： $$ P = (1/2)^{\\frac{m}{n} \\ln2} \\approx (0.6185)^{m/n} $$ （居然是黄金比例0.618😮） 如果我们想让其错误率小于$\\epsilon$，就需要计算 $$ (1/2)^{\\frac{m}{n} \\ln2} \u003c \\epsilon $$ 通过上式可得，$m$的取值范围为$m \u003e n\\log e \\log\\frac{1}{\\epsilon} \\approx 1.44 n \\log\\frac{1}{\\epsilon}$。所以该方法总的空间复杂度为$k$个hash函数和一个比特串的开销，即： $$ k \\log n + n \\log(1/\\epsilon) = (n + \\log n) \\log(1/\\epsilon) $$ 感觉占用的空间也不小啊~ 以上就完成了大概的分析，但其实专业的分析好像很复杂，我尝试了一下，没看懂😂 ","date":"2021-04-07","objectID":"/posts/21-04-07_bloom-filter/:3:0","tags":["hash"],"title":"Bloom Filter","uri":"/posts/21-04-07_bloom-filter/"},{"categories":["algorithm"],"content":"实现 TODO ","date":"2021-04-07","objectID":"/posts/21-04-07_bloom-filter/:4:0","tags":["hash"],"title":"Bloom Filter","uri":"/posts/21-04-07_bloom-filter/"},{"categories":["algorithm"],"content":"参考文献 http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html https://blog.csdn.net/jiaomeng/article/details/1495500 http://www.eecs.harvard.edu/~michaelm/postscripts/im2005b.pdf https://www.cs.utah.edu/~jeffp/teaching/cs5140-S16/cs5140/L12-Count-Min+Apriori.pdf http://www.cs.jhu.edu/~fabian/courses/CS600.624/slides/bloomslides.pdf ","date":"2021-04-07","objectID":"/posts/21-04-07_bloom-filter/:5:0","tags":["hash"],"title":"Bloom Filter","uri":"/posts/21-04-07_bloom-filter/"},{"categories":["algorithm"],"content":"摘要 本文主要介绍Count-Min Sketch，这是一种用来统计元素出现频率的数据结构，其基于hash函数进行构建，常用来解决\"Heavy-Hitter\"问题，即统计一个集合中经常出现的元素。本文除对算法原理进行介绍，更重要的是要对其进行数学分析，从而更好的理解该算法。 ","date":"2021-04-06","objectID":"/posts/21-04-06_count-min-sketch/:1:0","tags":["hash"],"title":"Count-Min Sketch","uri":"/posts/21-04-06_count-min-sketch/"},{"categories":["algorithm"],"content":"算法介绍 首先介绍算法的过程，初始化$t$个独立的hash函数$h_1, h_2, …,h_t$，每一个hash函数都是从集合$[n] \\to [k]$的映射。然后初始化一个二维矩阵，如下图所示： 我们假设$t=log(1/\\delta), k=2/\\epsilon$，至于$\\delta,\\epsilon$是什么，为什么那么赋值后面会解释，先说一下结论：当$t,k$选择上述值时，假阳性的值大于$m\\cdot \\epsilon$的概率小于$\\delta$。 对于具有m个元素的集合A，对其进行如下操作: Set all $C_{i,j}=0$ for i=0 to m do for j=0 to t do $C_{j,h_{j}(a_i)}$ += 1 当查找一个元素出现的次数时，只需要计算 $$\\check{f_{q}}=min C_{j,h_{j}(q)},j\\in [t]$$ 也就是说找到元素$q$映射到的位置当中的最小值，很明显通过此方法得到的值$\\check{f_q}$值肯定是大于等于实际值$f_q$的，因为$q$对应的值有可能与其他的值碰撞，从而产生假阳性，但是肯定不会产生假阴性。 那么到底会产生多少假阳性呢？ ","date":"2021-04-06","objectID":"/posts/21-04-06_count-min-sketch/:2:0","tags":["hash"],"title":"Count-Min Sketch","uri":"/posts/21-04-06_count-min-sketch/"},{"categories":["algorithm"],"content":"分析 我们希望最后的结果是能够以一定的概率保证$\\check{f_q} \u003c f_q + w$，那么下面需要做的就是怎么确定这个概率和$w$之间的关系呢？其实我们在上面已经假设$w=m\\cdot \\epsilon$，那么我们就将去求其概率。 首先我们假设一个符号$r_{i,j}$，表示由于$i$在hash函数$h_j$上导致的$q$的数量的增加，那么显然： $$ r_{i,j}= \\begin{cases} 1, \u0026 \\text{when collusion happen.} \\cr 0, \u0026 \\text{otherwise.} \\end{cases} $$ 也就是当碰撞发生时，其值为1，其他为0。如果我们想求出$r_{i,j}$的期望，就应该先求其概率。回顾该值的定义，该值定义为另外一个值$i$与$q$的碰撞所导致的值的增加，那么碰撞的概率是多少呢？如果所使用的hash函数理想的话，任意一个值与$q$的hash值相同的概率都为$1/k$。也就是说： $$ E(r_{i,j})=1/k $$ 那么容易求得： $$ E(r_{.,j})=\\sum_{i\\neq q}^m E(r_{i,j})=\\sum_{i\\neq q}^m 1/k \\approx m/k $$ 也就是说由在$h_j$处所产生的碰撞所导致的$C_{j,h_j(q)}$的值的增加–$r_{.,j}$的数学期望为$m/k$。那么根据马尔可夫不等式可以得出： $$ P(r_{.,j} \u003e w) \u003c E(r_{.,j})/w = m/kw $$ 回顾我们在一开始时设的$k=2/\\epsilon$，并将$w=m\\cdot \\epsilon$代入，可得 $$ P(r_{.,j} \u003e w) \u003c 1/2 $$ 我们以上只是分析了由$h_j$碰撞所导致的假阳性，根据算法可知，最后取得$f_q$值为所计算的hash函数的最小值，也就是说$f_q$假阳性的值取决于由所有hash函数导致的假阳性值的最小值。如果$f_q$的假阳性大于$w$，那么： $$ P(\\bar{f_q} - f_q \u003e w) = P(\\underset{j\\in t}{min}\\ r_{.,j} \u003e w) \u003c (1/2)^t $$ 又由上文可知，我们已经假设$t=log(1/\\delta)$，所以最后的结果为： $$ P(\\bar{f_q} - f_q \u003e w) \u003c \\delta $$ 这也就解释了我们一开始对于$t,k$的选值原因。最后的空间复杂度为： $$ t\\cdot \\log n + tk\\cdot \\log n = (\\frac{2}{\\epsilon} \\log m + \\log n)\\log \\frac{1}{\\delta} $$ ","date":"2021-04-06","objectID":"/posts/21-04-06_count-min-sketch/:3:0","tags":["hash"],"title":"Count-Min Sketch","uri":"/posts/21-04-06_count-min-sketch/"},{"categories":["algorithm"],"content":"代码实现 TODO😄 ","date":"2021-04-06","objectID":"/posts/21-04-06_count-min-sketch/:4:0","tags":["hash"],"title":"Count-Min Sketch","uri":"/posts/21-04-06_count-min-sketch/"},{"categories":["algorithm"],"content":"参考文献 https://www.cs.utah.edu/~jeffp/teaching/cs5140-S16/cs5140/L12-Count-Min+Apriori.pdf ","date":"2021-04-06","objectID":"/posts/21-04-06_count-min-sketch/:5:0","tags":["hash"],"title":"Count-Min Sketch","uri":"/posts/21-04-06_count-min-sketch/"},{"categories":["math"],"content":"最近在学习的时候遇到了一些数学证明，本身并不难，其中用到了马尔可夫不等式，但是不知道没有还是忘了，所以准备借此机会复习一下马尔可夫不等式和切比雪夫不等式（这个肯定学过）。针对这两则定理的证明网上很多很好的博客，包括维基百科，本文更像是重复造轮子😂。 ","date":"2021-03-21","objectID":"/posts/21-03-21_markov-and-chebyshev/:0:0","tags":["statistics"],"title":"马尔可夫与切比雪夫不等式","uri":"/posts/21-03-21_markov-and-chebyshev/"},{"categories":["math"],"content":"马尔可夫不等式 首先先把该不等式写下来： $$ P(x\u003e\\alpha) \u003c\\frac{\\mu}{\\alpha}, (x\u003e0) $$ 其中x的取值范围为$x\u003e0$，$\\mu$为x的数学期望。 看到这个公式，我的第一感觉是这个公式不对吧，公式里连方差都没有，也就是连离散程度都没有涉及怎么能够直接判定其范围呢？我甚至可以直接举出一个“反例”。 试着想象一下：假设x的分布像一条小船，中间概率小，几乎为0，两边大，几乎各占一半。$\\alpha$的值比较大，这里假设为10，并且假设在靠近0的地方x的概率密度很大，所以最后的结果是其期望为一个比较小的值，这里假设为1。 之所以认为其是反例的原因是，那么根据马尔可夫不等式，x大于$\\alpha$的概率为 $$ P (x\u003e\\alpha) \u003c\\frac{1}{10} $$ 根据图上所示，这明显“不对”啊，因为值主要分布在两端嘛，怎么可能大于$\\alpha$的概率仅为1/10呢？ 例子如如下图（这里图画的可能不太准确，其实也不可能准确）: “反例”“反例” \" “反例” -- 仔细思考后发现该想法是不对的，因为像是这样的图形是画不出来的。假如两边的两个峰值各占一半，那么其期望不可能特别小，其期望的值应该恰好在两个峰值之间，那么马尔可夫不等式的计算结果为1/2，好像符合实际情况😮 再假设其期望就是特别小，比如说1，然后两个峰值相差很大分别为0.1，10。那么根据杠杆原理（乱入😁），两个峰值的数据量之比肯定为10:1。那么根据马尔可夫不等式计算出的值1/10好像又是对的😮。 感觉不对，但是为啥举的例子又都是对的呢？后来仔细想想，应该是其条件限制了x的取值范围大于0，期望就相当于支点，距离支点越远，力矩越大，所以需要的力越小，嗯~~~听起来挺合理😁 以上只是我一开始的主观想象过程，下面介绍实际的证明： $$ \\begin{align} P(x\u003e\\alpha) \u0026 = \\int_\\alpha ^\\infty f(x)dx \\cr \u0026 = \\frac{1}{\\alpha}\\int_\\alpha^\\infty \\alpha f(x)dx \\cr \u0026 \u003c \\frac{1}{\\alpha}\\int_\\alpha^\\infty xf(x)dx \\cr \u0026 \u003c \\frac{1}{\\alpha}\\int_0^\\infty xf(x)dx \\cr \u0026 = \\frac{\\mu}{\\alpha} \\end{align} $$ 其数学证明很简单，值得说明的是该上界经过几次放缩，所以估计的很粗略，相对而言切比雪夫不等式就要准确一些。 ","date":"2021-03-21","objectID":"/posts/21-03-21_markov-and-chebyshev/:1:0","tags":["statistics"],"title":"马尔可夫与切比雪夫不等式","uri":"/posts/21-03-21_markov-and-chebyshev/"},{"categories":["math"],"content":"切比雪夫不等式 因为切比雪夫中引入了方差，所以感觉看着就比马尔可夫要靠谱些😂 $$ P(|x-\\mu |\u003e\\alpha) \u003c \\frac{\\sigma ^2}{\\alpha ^2} $$ 其中$\\mu$为期望，$\\sigma ^2$为方差。 该式的证明也很简单，直接代入马尔可夫不等式就可证明： $$ \\begin{align} P(|x-\\mu |\u003e\\alpha) \u0026 = P(|x-\\mu |^2\u003e\\alpha ^2) \\cr \u0026 \u003c \\frac{E(|x-\\mu|^2)}{\\alpha ^2} \\cr \u0026 = \\frac{\\sigma ^2}{\\alpha ^2} \\end{align} $$ 上式中的第二步转化之所以成立，是因为$E(|x-\\mu|^2)$恰好就是方差的定义啊。可见切比雪夫不等式其实就是对方差的另一种解释。不是方差恰好满足了这个式子，而是方差的定义使其一定满足该不等式。不难想象，如果方差改一下定义，那么切比雪夫不等式肯定以另一种形式出现。 另外，我学的教材中还有对切比雪夫不等式的另一种证明： $$ \\begin{align} P(|x-\\mu |\u003e\\alpha) \u0026 = P(|x-\\mu |^2\u003e\\alpha ^2) \\cr \u0026 = \\int_{|x-\\mu |^2\u003e\\alpha ^2} f(x)dx \\cr \u0026 \u003c \\int_{|x-\\mu |^2\u003e\\alpha ^2}\\frac{(x-\\mu)^2}{\\alpha ^2} f(x)dx \\cr \u0026 \u003c \\int_{-\\infty}^{\\infty}\\frac{(x-\\mu)^2}{\\alpha ^2} f(x)dx \\cr \u0026 = \\frac{\\sigma ^2}{\\alpha ^2} \\end{align} $$ 以上为我学的教材上的证明方法，可见切比雪夫不等式中的$|x-\\mu|$恰好可以和$f(x)$组成方差的计算公式。通过本博客希望自己对于上述两个不等式有更深的理解吧~😄 ","date":"2021-03-21","objectID":"/posts/21-03-21_markov-and-chebyshev/:2:0","tags":["statistics"],"title":"马尔可夫与切比雪夫不等式","uri":"/posts/21-03-21_markov-and-chebyshev/"},{"categories":[],"content":"关于我 程序员，现研究生在读，即将毕业（如果顺利）😂 Linux 用户 Vim 用户 markdown 用户 $\\LaTeX$ 用户 ","date":"2021-03-13","objectID":"/about/:0:0","tags":[],"title":"关于我","uri":"/about/"},{"categories":["math"],"content":" 主成分分析原理与实现--  主成分分析是一种矩阵的压缩算法，在减少矩阵维数的同时尽可能的保留原矩阵的信息，简单来说就是将 $n×m$的矩阵转换成$n×k$的矩阵，仅保留矩阵中所存在的主要特性，从而可以大大节省空间和数据量。最近课上学到这个知识，感觉很有意思，就在网上找一些博客进行学习，发现网上关于这方面的介绍很多，但是感觉都不太全面，单靠某一个介绍还是无法理解，当然这可能也跟个人基础有关。所以我在这里根据自己的理解写一个总结性的帖子，与大家分享同时也方便自己复习。对于主成分分析，可以参照以下几篇博客： PCA的数学原理该博客介绍了主成分中的数学原理，给出了比较清晰的数学解释。简单易懂，但是有一些细节并没有涉及到，所以还是不能完全理解。 PCA 原理：为什么用协方差矩阵介绍了为什么在降维的时候采用协方差矩阵，但是对于协方差矩阵的解释不详细。 关于协方差矩阵的理解对协方差矩阵的进行了详细的推导，解释了为什么可以通过$A A^T$来计算协方差矩阵。 矩阵求导、几种重要的矩阵及常用的矩阵求导公式对矩阵求导进行了介绍。提到了可能会用到的一些求导公式。 UFLDL 教程学习笔记（四）主成分分析对主成分的原理和使用进行了介绍。 ","date":"2021-03-04","objectID":"/posts/pca/:0:0","tags":["math","algorithm"],"title":"主成分分析原理与实现","uri":"/posts/pca/"},{"categories":["math"],"content":"1. 数学原理  数学原理的介绍部分可以参考文献1，该博客对主成分分析的数学原理进行了很直观的介绍。这里我根据自己的理解进行简单介绍。 图一（图片来源于文献 1）  对于一个坐标点$(3,2)$，我们知道其代表的意思是在二维坐标里其横坐标为3，纵坐标为2。其实这隐含了一个假设，即其横纵坐标的基为$(1,0)和(0,1)$。对于一般的二维向量，这似乎是大家的默认情况，就像随便给出一个数字$10$，大家会认为这是$10$进制表示，除非特殊标明，不会把它当作其他进制来理解。对于任意一个坐标点$(x,y)$，我们可以将其表示为： $$ \\begin{pmatrix} 1 \u0026 0 \\cr 0 \u0026 1 \\end{pmatrix} \\cdot \\begin{pmatrix} x \\cr y \\end{pmatrix} = \\begin{pmatrix} x \\cr y \\end{pmatrix} $$ 其中$\\begin{pmatrix} 1 \u0026 0 \\cr 0 \u0026 1 \\end{pmatrix}$的每一个行向量代表一个基向量。 如果我想更换基向量怎么办呢，如上图所示，如果我想知道$(3,2)$在$(\\sqrt{2}/2,\\sqrt{2}/2)与(-\\sqrt{2}/2,\\sqrt{2}/2)$基下的坐标值，该如何计算呢？回顾基本的数学知识，我们发现对于一个向量在一个基上的值其实就是该向量在该基向量上的投影。所以，已知基向量，我们可以很容易求得，对于一个向量，如$(3,2)$，其在基$(\\sqrt{2}/2,\\sqrt{2}/2)与(-\\sqrt{2}/2,\\sqrt{2}/2)$上的投影为： $$ \\begin{pmatrix} \\sqrt{2}/2 \u0026 \\sqrt{2}/2 \\cr -\\sqrt{2}/2 \u0026 \\sqrt{2}/2 \\cr \\end{pmatrix} \\cdot \\begin{pmatrix} 3 \\cr 2 \\end{pmatrix} = \\begin{pmatrix} 5\\sqrt{2}/2 \\cr -\\sqrt{2}/2 \\end{pmatrix} $$ 直观的图表示如上图所示。  再回到主成分分析上来，如果我们想对一个矩阵$A$进行降维，其中$A$为： $$ \\begin{pmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \\cr a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n} \\cr \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\cr a_{m1} \u0026 a_{m2} \u0026 \\cdots \u0026 a_{mn} \\cr \\end{pmatrix} $$ 行向量代表样本，列向量代表特征，所以其矩阵含义为m个具有n个特征的样本值。对于每一个样本具有的n个特征值，其特征值之间可能会存在很大的耦合，就如文献1中所列举的那样，特征M代表是否为男性，特征F代表是否为女性，因为一个人的性别只能为其中的一个（不考虑特殊情况）。所以这两个特征只留一个就行了，所以就可以省下一半的空间。这个例子有些极端，但是并不影响理解。 图二（图片来源于网络）  同样对于一个具有n个特征的集合来说，很难说这n个特征都是完全有必要的，所以我们就想办法来精简一些特征。选取少于n个的基向量组，将数据投影在这个向量组上，减少空间的同时又能保证信息量。首先需要明确的一点是什么才算好的基向量？首先举一个将二维空间的数据投影到一维空间的情况。如上图所示，对于空间中的这些点，我们应该怎么投影才能够尽可能的保持数据的信息量呢？通过上图中可以看出，如果将数据投影到PC1上，那么所有的数据点较为分散，与之相反，如果投影到PC2上，则数据较为集中。考虑一个极端的情况，假如所有的点在投影之后全部集中在一个点上，这样好吗？当然不！如果所有的点都集中到一个点上，那就说明所有的点都没有差别，信息全部丢失了。所以我们希望当数据点投影到某个坐标轴之上以后，数据越分散越好，而衡量一组数据是否发散恰好有一个统计名词“方差”，也就是说投影过后的点值方差越大越好。 同时，如果数据被投影到多个基向量上，那么我们希望这些基向量之间的耦合程度越小越好，也就说基向量之间应该是正交的，如图三所示（建议点击链接去相应网站查看3D演示）。因为如果不考虑基向量之间的正交性，只考虑方差最大的话，那么所求得的所有的基向量其实都是一样的。关于在不同的基向量上的投影的线性相关度也有一个度量标准–协方差。那么我们的目标明确了，使得相同特征之间方差越大越好，不同特征之间协方差越小越好。 图三（参考文献【6】）  那么这些方差，协方差什么的怎么计算呢？这里可以先给出一个结论，将$A$向量的每一列减去该列的平均值得到一个新的$A$矩阵。然后计算$Cov=1/m \\cdot A^T\\cdot A$，得到一个$n\\times n$的矩阵$Cov$，那么$Cov$的对角线上的元素$c_{ii}$即为第i个特征的方差，对于其他元素$c_{ij}$表示第i个和第j个特征的协方差，很明显该矩阵是对称矩阵。关于该矩阵的计算方式可以参考文献3，其介绍的很详细，这里就不再重复。需要注意的一点是这里$Cov=1/m \\cdot A^T\\cdot A$是因为A矩阵的列向量为特征，所以才这样计算。如果A矩阵的行列向量所表达的含义相反则$Cov=1/m \\cdot A\\cdot A^T$。  已经知道了计算协方差矩阵的方法，下面看一下怎么跟我们要做的结合在一起。再次总结一下我们要做的是什么，对于一个已有的矩阵$A$，我们希望将它投影在一组新的基空间上，使之矩阵大小得到压缩。即： $$ D_{m,N} = A_{mn} \\cdot P_{nN}, \\ \\ \\ \\ given (N \u003c n) $$ 我们要做的就是将n个特征压缩为N个特征。对于压缩过的数据投影，根据上面的叙述可知，我们希望对于相同特征之间方差越大越好，不同特征之间协方差越小越好，并且我们已经知道该如何计算方差和协方差了。 $$ Cov(D)_ {N,N} = D^T \\cdot D = P^T A^T A P. $$ 所以现在的目标很明确，我们要做的就是求得$P$，使得$Cov(D)$的对角线元素尽可能大，非对角线元素尽可能小。学过线性代数的应该都知道，对于$A^T A$矩阵来说，其特征向量组就满足这一条件。因为已知$A^T A$矩阵为对称矩阵，所以可知： $$ P^T (A^T A) P = P^{-1} (A^T A) P = \\Lambda $$ 其中$\\Lambda$为$A^T A$的特征值组成的对角阵，$P$为相应的的特征向量组。  至此，我们就找到了进行主成分分析的方法： 首先对矩阵A进行处理，使得其每一列（或者行）减去其相应列的平均值，使得每一列的平均值都为0，然后计算$B = A^TA$。 求$B$矩阵的特征值和特征向量，将特征值进行排序，并选取前N大的特征值，选取其对应的特征向量组成特征向量组$P_{nN}$。 $D_{m,N} = A_{mn} \\cdot P_{nN}$即为最终想要得到的值。 ","date":"2021-03-04","objectID":"/posts/pca/:1:0","tags":["math","algorithm"],"title":"主成分分析原理与实现","uri":"/posts/pca/"},{"categories":["math"],"content":"2.实验验证  下面我们对该算法进行实际的实现，为了更好的了解PCA的工作原理，同时又保证程序的计算速度，我才用了C语言进行实现，并借助OpenBLAS库进行高效的矩阵运算。OpenBLAS是BLAS标准的一个开源实现，据说也是目前性能和维护的最好的一个。BLAS是Basic Linear Algebra Subprograms的简称，是一个矩阵运算的接口标准。既然是接口标准，那么所有根据该标准的实现都具有相同的使用方式和功能。相似的实现还有BLAS、MKL、ACML等，我使用OpenBLAS进行实现，因为其实现不依赖于任何平台，具有良好的性能，而且亲测易于安装。下面将附上我的实现代码： //矩阵运算部分 Matrix.cpp #include\u003ciostream\u003e#include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e//#include \"mkl.h\" #include\"OpenBLAS/cblas.h\"class Matrix { public: //Print matrix; bool printMatrix() const; //get r. int getr() {return r;} //get l. int getc() {return c;} //get a. float *geta() {return a;} //normalization. void nmlt(); //Compute Coevariance of a, aTxa void coev(Matrix \u0026c); //Default constructor. Matrix():a(NULL), r(0), c(0) {} //Constructor with matrix pointer and dimension. Matrix(float *aa, int rr, int cc): a(aa), r(rr), c(cc) {} //Constructor with only dimension, should allocate space. Matrix(int rr, int cc): r(rr), c(cc) { a = new float[rr*cc]; } //Destructor. ~Matrix() {delete []a; a=NULL;} protected: //Matrix pointer. float *a; //Dimension n, order lda int r,c; }; extern bool printArray(float *p, int n); class SquareMatrix:public Matrix { public: //Default constructor. SquareMatrix(float *aa, int nn):Matrix(aa, nn, nn), n(nn) {} SquareMatrix(int nn): Matrix(nn, nn), n(nn){} //Destructor. ~SquareMatrix() {} //Get eigenvalue and eigenvector; int ssyevd(float *w); private: int n; }; bool Matrix::printMatrix() const { int i=0, j=0; float temp(0); for(i=0; i\u003cr; i++) { for(j=0; j\u003cc; j++) { temp = *(a+c*i+j); printf(\"%7.3f\\t\", temp); } std::cout\u003c\u003cstd::endl; } } int SquareMatrix::ssyevd(float *w) { lapack_int res = 0; res = LAPACKE_ssyevd(LAPACK_ROW_MAJOR, 'V', 'U', n, a, n, w); if(res == 0) { return res; } else { std::cout\u003c\u003c\"ERROR:\"\u003c\u003cres\u003c\u003cstd::endl; exit(-1); } } void Matrix::coev(Matrix \u0026cc) { nmlt(); cblas_sgemm(CblasRowMajor, CblasTrans, CblasNoTrans, c, c, r, 1.0/r, a, c, a, c, 0.0, cc.geta(), c); } void Matrix::nmlt() { int i=0,j=0; float av = 0.0; for(i=0;i\u003cc;i++) { av = 0.0; for(j=0;j\u003cr;j++) { av+=*(a+i+j*c); } av = av/r; for(j=0;j\u003cr;j++) { *(a+i+j*c) -= av; } } } bool printArray(float *p, int n) { for(int i=0; i\u003cn; i++) { printf(\"%7.3f\\t\", p[i]); } std::cout\u003c\u003cstd::endl; return true; } //PCA部分 PCA.cpp #include\u003ciostream\u003e#include\u003cstdio.h\u003e#include\u003cstdlib.h\u003e//#include \"mkl.h\" #include\"OpenBLAS/cblas.h\"#include\"Matrix.h\"#include\"PCA.h\" #define N 5 #define T 0.8f const char SEP = ','; static unsigned int R = 5; static unsigned int C = 5; int main(int argc, char *argv[]) { // float *A = new float [N*N] // { // 1.96f, -6.49f, -0.47f, -7.20f, -0.65f, // -6.49f, 3.80f, -6.39f, 1.50f, -6.34f, // -0.47f, -6.39f, 4.17f, -1.51f, 2.67f, // -7.20f, 1.50f, -1.51f, 5.70f, 1.80f, // -0.65f, -6.34f, 2.67f, 1.80f, -7.10f // }; if(argc \u003c= 1) { printf(\"Usage: PCA [INPUT FILE] [OUTPUT FILE] [ROW] [COLUM]\\n\"); printf(\"INPUT FILE: input file path.\\n\"); printf(\"OUTPUT FILE: output file path.\\n\"); printf(\"ROW: Row of matrix.\\n\"); printf(\"COLUM: Colum of matrix.\\n\"); exit(0); } FILE *input = fopen(argv[1], \"r\"); FILE *output = fopen(argv[2], \"w+\"); R = atof(argv[3]); C = atof(argv[4]); printf(\"Input:%s\\nOutput:%s\\nR:%d\\nC:%d\\n\",argv[1], argv[2], R, C); float *I = new float[R*C](); //float *O = new float[R*C](); char *label = new char[R]; //read matrix. readMtx(input, I, label); SquareMatrix cov = SquareMatrix(C); float *eValue = new float[C](); Matrix m = Matrix(I, R, C); Matrix n = Matrix(R, C); // m.printMatrix(); //compute coveriance matrix. m.coev(cov); //compute eigenvalue and eigenvector of coveriance matrix. cov.ssyevd(eValue); //Compute compressed matrix. eMtx(m, cov, n); //n.printMatrix(); saveMtx(output, n.geta(), label); fclose(input); fclose(output); delete []label; delete []eValue; return 0; } //eigen matrix void eMtx(Matrix\u0026a, Matrix\u0026b, Matrix\u0026r) { cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, a.getr(), b.getc(), a.getc(), 1.0, a.geta(), a.getc(), b.geta(), b.getc(), 0.0, r.geta(), b.getc()); } bool readUtl(FILE *f, char sep) { char c; if((c=f","date":"2021-03-04","objectID":"/posts/pca/:2:0","tags":["math","algorithm"],"title":"主成分分析原理与实现","uri":"/posts/pca/"},{"categories":["math"],"content":"欧几里得算法 ","date":"2021-03-04","objectID":"/posts/euclid/:1:0","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"原理 欧几里得算法是一种快速计算最大公约数的算法，对于任意的两个数$(a,b)$，其最大公约数表示为$gcd(a,b)$，根据欧几里得算法，$gcd(a,b)=gcd(b,a\\mod b)$ 。证明如下： 如果$b\u003ea$，显然成立；因此只需考虑$b \u003c a$的情况。根据初等数学知识，可知$a,b$的关系可表示为$a=qb+r$，其中$q$为商，$r$为余数。 对于$(a,b)$的最大公约数$g1=gcd(a,b)$，当然$g1|a,g1|b$（$g1|a$表示$g1$整除$a$），所以易知对于$r=a-qb$，同样满足$g1|r$； 又因为$a\\mod b=r$，所以对于$a,b$的最大公约数$g1$，同样满足$g1|(a\\mod b),g1|b$，即$(b,a\\mod b)$的最大公约数至少为$g1$，即$gcd(b,a\\mod b)\u003eg1=gcd(a,b)$。 反过来，对于$(b,a\\mod b)$的最大公约数$g2=gcd(b,a\\mod b)$，同样满足$g2|a, g2|b$，即$gcd(a,b)\u003eg2=gcd(b,a\\mod b)$。 因此$gcd(a,b)=gcd(b,a\\mod b)$证明成立。下面对该算法进行实现。 ","date":"2021-03-04","objectID":"/posts/euclid/:1:1","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"实现 #include \u003ciostream\u003e using namespace std; int euclid(int a, int b) { if (b!=0) { return euclid(b, a%b); } else { return a; } } int main() { int a(0),b(0); cin \u003e\u003e a \u003e\u003e b; cout \u003c\u003c euclid(a,b); return 0; } ","date":"2021-03-04","objectID":"/posts/euclid/:1:2","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"拓展的欧几里得算法 ","date":"2021-03-04","objectID":"/posts/euclid/:2:0","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"原理 拓展的欧几里得算法在密码学中有着重要的应用，现给出定理： 对正整数a，b；总是存在一组整数X,Y，使得$Xa+Yb=gcd(a,b)$成立，且$gcd(a,b)$为满足这种条件的最小整数。 这里不对该定理进行证明，欧几里得算法给出了在已知$a，b$的情况下求$gcd(a,b)$的方法，但是如果想要求得X，Y的值，就要求助于拓展的欧几里得算法。怎么才能从欧几里得算法的计算过程当中得到我们想要求解的值呢？我们再次详细回顾欧几里得算法的求解过程。 对于已知整数$a,b$，我们的算法求解过程如下： $a$ $b$ 余数$r$ 商$q$ a b $r_1=a\\mod b$ $q_1=a/b$ b $r_1$ $r_2=b\\mod r_1$ $q_2=b/r_1$ $r_1$ $r_2$ $r_3=r_1\\mod r_2$ $q_3=r_1/r_2$ … … … … $r_{n-1}$ $r_n$ $r_{n+1}=r_{n-1}\\mod r_n$ $q_{n+1}=r_{n-1}/r_n$ 逐步计算，直到某一步出现$r_{n-1}\\mod r_{n}=0$的情况，这时候就找到了最大公约数，最大公约数即为$r_n$，以上就是欧几里得算法的全过程。通过这个过程当中多产生的一些中间结果我们能不能求得$X,Y$的值呢？下面进行两种求解方法的推导。 ","date":"2021-03-04","objectID":"/posts/euclid/:2:1","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"递归求解 根据上面的表格我知道，$Xa+Yb=gcd(a,b)$，并且对于中间所求解的每一步我们所得到的$r_i$都满足$X_i\\cdot r_i+Y_i\\cdot r_{i+1}=gcd(a,b)$，因为很明显每一对$r_i,r_{i+1}$都满足最大公约数为$gcd(a,b)$，这也是欧几里得算法的原理。 我们试着寻找$(X_i,Y_i),(X_{i+1},Y_{i+1})$之间的递推关系，由以上阐述可知: $$ \\begin{cases} X_i\\cdot r_i+Y_i\\cdot r_{i+1}=gcd(a,b), \u0026\\text{(1)} \\cr X_{i+1}\\cdot r_{i+1}+Y_{i+1}\\cdot r_{i+2}=gcd(a,b),\u0026\\text{(2)} \\end{cases} $$ 为了将上式转换成$r_i$的方程组，我们使用$r_{i+1},r_{i+2}来表示r_i$，通过以上可知$r_i=r_i/r_{i+1}\\cdot r_{i+1}+r_{i+2}$，将该式带入上式（1），并将两式合并可得： $$ X_i\\cdot (r_i/r_{i+1}\\cdot r_{i+1}+r_{i+2})+Y_i\\cdot r_{i+1}=X_{i+1}\\cdot r_{i+1}+Y_{i+1}\\cdot r_{i+2} $$ 进一步化简可得： $$ (X_i\\cdot r_i/r_{i+1}+Y_i)\\cdot r_{i+1}+X_i\\cdot r_{i+2}=X_{i+1}\\cdot r_{i+1}+Y_{i+1}\\cdot r_{i+2} $$ 根据系数相等的原则可得： $$ \\begin{cases} X_i\\cdot r_i/r_{i+1}+Y_i=X_{i+1}, \u0026\\text{(1)}\\cr X_i=Y_{i+1},\u0026\\text{(2)} \\end{cases} $$ 以上就得到了$(X_i,Y_i),(X_{i+1},Y_{i+1})$之间的递推关系，那么我们接下来的工作就是找到一对可以求出其值的$(X_i,Y_i)$，通过以上可知当出现某一次计算使得$r_{i}\\mod r_{i+1}=0$时，我们可知对于$X_i\\cdot r_i+Y_i\\cdot r_{i+1}=gcd(a,b)$，满足$gcd(a,b)=r_{i+1}$，那么很显然$X_i=0,Y_i=1$。于是我们就得到了一对$(X_i,Y_i)$的值，我们已经知道了最后一对$r_{i},r_{i+1}$所对应的$(X_i,Y_i)$才能够推知前面的值，所以我们的推导是从后往前推的，因此我们将上面的递推关系稍微变换一下形式： $$ \\begin{cases} X_i=Y_{i+1},\u0026\\text{(1)}\\cr Y_i=X_{i+1}-Y_{i+1}\\cdot r_i/r_{i+1}, \u0026\\text{(2)} \\end{cases} $$ 此时我们就得到了推导关系和初值，通过计算我们就可以求得满足$Xa+Yb=gcd(a,b)$的$X,Y$值。下面通过代码对其进行实现： #include \u003ciostream\u003e using namespace std; void extEuc(int a, int b, int\u0026x, int\u0026y) { int rx,ry; int r(0); if (a%b==0) { x=0;y=1; return; } else { r = a%b; extEuc(b, r, rx, ry); x = ry; y = rx - ry*a/b; return; } } int main() { int a,b; int x,y; cin \u003e\u003e a \u003e\u003e b; extEuc(a, b, x, y); cout \u003c\u003c x \u003c\u003c' '\u003c\u003c y \u003c\u003c endl; return 0; } 输入42 2017可求得输出为-48，1。 ","date":"2021-03-04","objectID":"/posts/euclid/:2:2","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["math"],"content":"迭代求解 较多的递归调用可能会影响计算速度，所以我们接下来推一下迭代的计算方式，已知上面表格中所列欧几里得算法的计算步骤。已知$gcd(a,b)$是满足该集合的最小值$\\lbrace Xa+Yb | X,Y\\in Z \\rbrace$，已知对于每一步所产生的余数均能被$gcd(a,b)$整除，现在考虑每一步迭代所产生的余数满足的等式： $$ \\begin{cases} r_i=X_i\\cdot a+Y_i\\cdot b \\cr r_{i+1}=X_{i+1}\\cdot a + Y_{i+1}\\cdot b \\end{cases} $$ 且已知$r_i, r_{i+1}$满足$r_{i-1}=r_{i-1}/r_i\\cdot r_i+r_{i+1}$，将上面两式代入到该式，可得： $$ r_{i-1}=(r_{i-1}/r_i\\cdot X_i+X_{i+1})\\cdot a+(r_{i-1}/r_i\\cdot Y_i +Y_{i+1})\\cdot b. $$ 值得注意的是此处的$X_i,Y_i$与递归方法中的值含义不同。根据上式可推知以下递推关系： $$\\begin{cases} X_{i+1}=X_{i-1}-r_{i-1}/r_i\\cdot X_i \\cr Y_{i+1}=Y_{i-1}-r_{i-1}/r_i\\cdot Y_i \\end{cases}$$ 已知中间的递推关系，关键是考虑如何判断循环的起始值和结束条件，对于$a,b$也可看做是余数$r_i$，那么对于$a,b$来说，其满足的值为： $$\\begin{cases} a = a\\cdot 1 + b\\cdot 0\\cr b = a\\cdot 0 + b\\cdot 1 \\end{cases}$$ 所以就得到了两对$(X,Y)$的值，分别为$(1,0),(0,1)$，并且已知$r_i$之间的递推关系为$r_{i+1}=r_{i-1}\\mod r_i$。我们也知道循环结束的条件为$r_i=gcd(a,b)$，其最后的形式为$Xa+Yb=gcd(a,b)$，其直接判断方式为$r_{i-1}\\mod r_i=0$，然后我们就得到了最终的$X,Y$值，根据以上递推形式，我们有以下实现： #include \u003ciostream\u003e using namespace std; int main() { int a,b; int x1(1),y1(0),x2(0),y2(1); int temp; cin \u003e\u003e a \u003e\u003e b; while (a%b!=0) { temp = x2; x2 = x1 - a/b*x2; x1 = temp; temp = y2; y2 = y1 - a/b*y2; y1 = temp; temp = a%b; a = b; b = temp; } cout \u003c\u003c x2 \u003c\u003c' '\u003c\u003cy2\u003c\u003cendl; return 0; } 输入42 2017可求得输出为-48，1。 这里有一个用尽可能多的程序语言实现求逆元的网站，大家也可以参考这里的不同实现。 参考文献 [1] Katz J，Lindel Y．Introduction to Modern Cryptography—Principle and Protocol现代密码学——原理与协议【M】任伟．北京：国防工业出版社．2010：10-15． ","date":"2021-03-04","objectID":"/posts/euclid/:2:3","tags":["math"],"title":"Euclid Algorithm and Extended Euclid Algorithm.","uri":"/posts/euclid/"},{"categories":["record"],"content":" The first blog. ","date":"2021-03-04","objectID":"/posts/hello-world/:0:0","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"博客搭建记录 在阅读了众多的博客搭建教程之后，最终选择了使用github + hugo进行搭建，主题为even. 希望借此博客在互联网上留下一点有价值的东西，同时作为自己的学习笔记，温故而知新。 ","date":"2021-03-04","objectID":"/posts/hello-world/:1:0","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"软件安装 首先进行相应软件的安装，具体可以参考官方文档的安装步骤。本文以ubuntu举例说明。在ubuntu上可直接使用apt进行安装，但是使用该方法安装的hugo软件版本过低，会导致本文所使用的主题even无法使用（我所使用的even要求最低版本为0.60），而且这个问题可能在其他主题上也存在。总而言之，建议直接安装最新版本，可直接到release下载。 ","date":"2021-03-04","objectID":"/posts/hello-world/:1:1","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"网站和主题配置 软件安装好了之后，可以创建一个文件夹作为根目录(如mkdir blog)并使用git init进行初始化，然后在该目录下进行hugo的初始化，初始化操作为 hugo new site [blogs name] 然后在该目录下就会创建一些文件夹，如： README.md archetypes config.toml content public resources themes 文件夹的具体作用我正在继续摸索，现在大概知道config.toml是全局配置文件；content文件夹中放置的是博客的内容，如本博客的路径就是content/post/hello-world；themes中所存放的就是主题文件，文件夹下可有多个主题，但是在使用的时候只能指定其中一个；public中所存放的是一些经过编译的网页内容，即使用markdown编写的博客经过编译以后会放到这个文件夹里，但具体的组织结构还没搞明白，待后续研究；archetypes中存放的好像是模板之类的东西，同样待后续研究。 接下来讨论怎么设置主题，经过一段时间纠结的筛选后，决定暂时使用even主题，主要原因有： 主题看来还算简洁 维护还算活跃 该主题是一个博客性质的主题，比较符合目前需求 该主题的开发者是国人同胞，可能比较符合国人的应用习惯 选定主题后，就将该主题clone到themes文件夹下并命名为even。然后将该仓库添加为本仓库的子模块。 git submodule add https://github.com/olOwOlo/hugo-theme-even ./themes/even 然后可以参考even主题的教程，将其配置文件进行拷贝和自行配置。其配置方面的文档较少，但好处是其配置文档中都使用了中文对其作用和用法进行了大概的注释，同样也可以根据需求进行增添内容，具体细节将后续进行学习。 ————21/04/07更新———– 感觉even有些功能不理想，比如说分类和标签没有任何区分度，并且作者似乎已经停止开发了，所以准备转到LoveIt的继任者CodeIT上，不过even也有优点，就是作者是国人，所以一些特性（如百度统计、不蒜子等）还是挺符合国人习惯和应用需求的。 但是写博客不就是为了折腾吗？😂，把仅有的几个博客来回迁移:laugh:。选定新的主题后，准备进行迁移，下面准备讲述更新过程。使用这两个主题的时候都会遇到一个问题，就是数学公式的显示问题，感觉两个主题都有一些不尽如人意的地方，接下来将讲述我遇到的问题，以及目前所采用的方式。希望以后能够有机会了解hugo的细节，从而更好的解决该问题。 首先是even主题，该主题使用的是mathjax进行公式的渲染，经过网上了解，mathjax是一个很成熟的解决方案，所以其对数学公式的支持还是很完善的，但是在使用较复杂的数学公式环境过程中还是遇到了一个问题，如: \\begin{align} x \u0026= y + 1 \\\\ y \u0026= z + 2 \\end{align} 在$\\LaTeX$中是没有问题的，但是在hugo就无法被正确渲染，只有将换行符\\\\更改为\\\\\\\\才能正常工作，好像看到网上有相关的讨论（没有记录），说导致该问题的原因是markdown编译器在进行解析的时候会将第一斜杠解释为转义，那么最后的结果是只剩一个斜杠，所以如果想让其最后仍然有两个斜杠，则不得不用四个斜杠。虽说敲四个斜杠是麻烦了点，但是好歹问题算是大概解决了。 后来试用CodeIT主题时则出现了更严重的问题，主要是因为该主题使用的是据说是性能更好的$KaTeX$渲染器。该渲染器作为托管在github的开源项目还是挺受欢迎的，但是katex对于公式的支持就不那么完善了，截止到目前的最新版本0.13.0，刚能够支持诸如align,align*等环境。而CodeIT使用的仍然是0.11.1的老版本，但这还不是主要问题，主要问题是原本在mathjax中可行的方案在katex中不可行了，比如根据文档katex v0.11.1中是支持aligned环境的，但是以下代码并不能够被正确渲染： \\begin{aligned} x \u0026= y + 1 \\\\\\\\ y \u0026= z + 2 \\end{aligned} 该代码可以在even主题下正常工作，但是无法在CodeIT在工作，经网上搜索，发现了该解决方案，经该方案介绍，使用如下代码可正常工作： \\begin{aligned} x \u0026= y + 1 \\cr y \u0026= z + 2 \\end{aligned} 其效果为： $$ \\begin{aligned} x \u0026= y + 1 \\cr y \u0026= z + 2 \\end{aligned} $$ 主要改动为将斜杠更换为\\cr，经测试可以正常工作，然后将该方式在even主题中测试也可以工作，所以就计划采用这种方式来代替双斜杠的功能，虽然感觉像是最后对问题的妥协，但是好歹是解决了该问题😂 后来有对问题做进一步的探索，做法是在浏览器中查看网页的源代码，我发现使用斜杠做为换行符的方式都会在公式行的最后引入一个\u003cbr\u003e标签，如下所示： \\begin{aligned} x \u0026amp;= y + 1 \\\\ \u003cbr\u003e y \u0026amp;= z + 2 \\end{aligned} 具有标签的代码在使用mathjax渲染器的时候是可以被正常渲染的，但是在katex中却不行。而使用\\cr进行换行则不会引入\u003cbr\u003e标签，因此在katex中可用。 最后附上将换行符更改为\\cr的命令: sed -i 's/\\\\\\\\\\\\\\\\/\\\\cr/' [blogname].md ————21/04/08更新———– 除上述所示问题外，今天又遇到了另外一个问题，那就是在公式中使用特殊字符（如%）时需要进行转义，一般写为\\%，但是这又会遇到一个问题，就是在$符号之间的字符不能够像在 ` 符号中那样被免于转义。也就是说\\%中的斜杠会在markdown解析的过程中解析为转义字符，因此到公式解析器的时候剩下的就只剩一个%符号了，所以需要使用两个符号才行。关于这个问题，感觉主要问题还是在markdown解析器那里没有执行正确的解析。当然，以上只是我的猜想，有时间我会去验证的。 知道问题之后的解决方式呢？如果实在不得不用特殊字符的转义，那就使用上述方法，可以解决。如果不是必要，比如我这里就是将%作为模运算符号，其实math里有专门的符号\\mod表示该含义，所以出于兼容性期间，决定使用\\mod符号，因为万一哪一天markdown解析器可以正常解析了，岂不是还要把两个斜线换成一个。 同时这里有一个总结：在markdown的公式环境中尽量减少使用转义符👉\\👈 ","date":"2021-03-04","objectID":"/posts/hello-world/:1:2","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"写博客 上面已经进行了大概的配置，下面将介绍怎么写一篇博客。首先使用 hugo new post/hello-world 创建一个新的博客，该命令将创建一个文件：content/post/hello-world.md。该文件会包含一个文件头 title: *** date: 202*** draft: true draft一栏默认为true，如果想要发布该博客，需要将其修改为false。 hugo的一个好处就是可以边写博客边进行调试，其具体操作为：在主目录下（即blog/）运行 hugo server -D 该命令将启动一个本地服务，端口号为1313，在本地使用浏览器访问：http://localhost:1313即可在线预览自己的博客内容。每次保存文件时，hugo都会自动进行编译，速度很快，几乎实现了markdown的同步预览，非常方便！ 在发布之前应该使用 hugo -D 编译一下，至此已经可以实现基本的功能 ","date":"2021-03-04","objectID":"/posts/hello-world/:1:3","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"使用github发布博客 首先要有一个github账号，然后创建一个新的仓库，其名字为：[your github id].github.io，关于这方面的教程非常多，也很简单，这里就不再赘述。然后其部署可参考https://gohugo.io/hosting-and-deployment/hosting-on-github/#build-hugo-with-github-action。其操作非常方便，只需要创建一个文件，然后将一些github action代码复制进去就行了。具体原理后续研究…(这里不得不感叹一句，github的功能比我想象的要强大多了!) 然后就是将本地文件(即blog/文件夹)push到所创建的仓库中。最后需要注意的是在上面所创建的仓库的设置页面要进行一定的设置，其位置为setting-\u003egithub pages-\u003esource，需要将branch更改为gh-pages，路径为root，在这里还可以设置定制化的域名等，这里先暂时不研究。通过以上设置应该就可以成功访问页面了。如本博客主页为：http://xinyu-yang.github.io 还有很多功能待后续学习更新… ","date":"2021-03-04","objectID":"/posts/hello-world/:1:4","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":["record"],"content":"图床 以前用CSDN和博客园写的时候根本不用考虑这个问题，但是现在自己搭建博客的时候就需要好好考虑一下这个问题。一开始惊喜的发现有很多的免费图床网站（比如imgbb），开心的以为这个问题解决了，后来发现没那么简单。因为这些免费的图床往往有很多限制，比如上面举例说的这个imgbb，该网站一开始用着还行，可是过几天再在博客里加载图片时只能加载出缩略图了。 后来就寻求解决方案，最后的决定是仍然使用开源的代码托管网站托管图片，把白嫖进行到底😂。最终我决定使用PicGo+(Gitee/Gitlab/Github)实现。 因为Gitee是国内的网站，加载较快，另外就是还没有使用Gitee托管代码的打算，所以不如注册个账号专门用来托管图片，综合以上原因，最终使用了Gitee。但是Gitee也有很多缺点，缺点之一就是空间太小了（这里不得不吐槽一句，本来就是模仿者，又那么小气，没有任何优势，难怪没人用啊~）。 下图是Gitee示例： 测试图片测试 \" 测试图片 最后不得不说一下，感觉PicGo真的是开源代码的典范，自己提供一个框架和一套接口，其他人可以按照接口开发各种各样的代码。我感觉对于实用性的工具应用，这种开发方式非常合适。 功能强大，但不臃肿，用户有足够多的定制选择权。 ","date":"2021-03-04","objectID":"/posts/hello-world/:1:5","tags":["blog"],"title":"Hello World","uri":"/posts/hello-world/"}]